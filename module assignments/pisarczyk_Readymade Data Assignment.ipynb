{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readymade Data Module Assignment\n",
    "## NYC 311 Service Request Analysis\n",
    "\n",
    "**Student Name:** Nick Pisarczyk\n",
    "\n",
    "**U-M Unique Name:** npisar\n",
    "\n",
    "**Research Question:** State your chosen research question here\n",
    "\n",
    "---\n",
    "\n",
    "**BEFORE YOU START:**\n",
    "1. Read the assignment instructions on Canvas carefully.\n",
    "2. Make a copy of this notebook and work on your own copy.\n",
    "3. Understand the dataset before you start cleaning and analyzing. NYC Open Data has a nice portal and a data dictionary for exploring their datasets.\n",
    "4. NYC 311 is a **very large** dataset. When you are fetching data from the portal or API, we would recommend you to first think about your research questions and start with a small subset of the data and then increase the size of the data as you get more comfortable with the data. Generally, you do **not** need to use the entire dataset to answer your research question.\n",
    "5. This notebook serves as a template. You can add more cells or make adjustments as you see fit. But make sure to keep all the sections mentioned in the assignment instructions. Also, format your notebook properly for better readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Statement\n",
    "\n",
    "Describe your data source here. Include:\n",
    "- Where you obtained the data (URL or API endpoint)\n",
    "- What subset you're analyzing (dates, geography, etc.)\n",
    "- Any filters or sampling you applied\n",
    "- File size/number of records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# You can import any libraries you may need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams'figure.figsize' = (12, 6)\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A: Load from downloaded CSV file\n",
    "\n",
    "**Note**: If you are running the notebook using `colab` kernel, you **cannot** directly import the data from your own laptop. Please see the class repo README files for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your downloaded data\n",
    "# df = pd.read_csv('311_Service_Requests.csv', \n",
    "#                  parse_dates='Created Date', 'Closed Date',\n",
    "#                  low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Load from Socrata API (recommended for smaller datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install sodapy # UNCOMMENT THIS LINE IF YOU NEED TO INSTALL sodapy: \n",
    "\n",
    "# from sodapy import Socrata\n",
    "\n",
    "# # Example: Get 100,000 records from 2023 for Brooklyn\n",
    "# client = Socrata(\"data.cityofnewyork.us\", None)\n",
    "# results = client.get(\"erm2-nwe9\", \n",
    "#                      where=\"created_date >= '2023-01-01' AND borough = 'BROOKLYN'\",\n",
    "#                      limit=100000)\n",
    "# df = pd.DataFrame.from_records(results)\n",
    "\n",
    "# # Convert date columns\n",
    "# df'created_date' = pd.to_datetime(df'created_date')\n",
    "# df'closed_date' = pd.to_datetime(df'closed_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Data Description\n",
    "\n",
    "You can describe the data in many ways. Here are some baseline requirements:\n",
    "- Display basic information about the dataset (what are the relevant variables? What are their types? How many observations are there?)\n",
    "- Conduct summary statistics of the relevant variables\n",
    "- Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can have as many cells as you want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning\n",
    "\n",
    "Document your cleaning decisions and rationale here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example cleaning steps (customize based on your needs)\n",
    "\n",
    "# 1. Remove rows with missing essential data\n",
    "# df_clean = df.dropna(subset='created_date', 'complaint_type')\n",
    "\n",
    "# 2. Filter to specific time period if needed\n",
    "# df_clean = df_clean(df_clean'created_date' >= '2023-01-01') & \n",
    "#                     (df_clean'created_date' < '2024-01-01')\n",
    "\n",
    "# 3. Create derived variables\n",
    "# Example: Calculate response time\n",
    "# df_clean'response_time_hours' = (\n",
    "#     (df_clean'closed_date' - df_clean'created_date').dt.total_seconds() / 3600\n",
    "# )\n",
    "\n",
    "# Example: Extract temporal features\n",
    "# df_clean'hour' = df_clean'created_date'.dt.hour\n",
    "# df_clean'day_of_week' = df_clean'created_date'.dt.dayofweek\n",
    "# df_clean'month' = df_clean'created_date'.dt.month\n",
    "\n",
    "print(f\"Original dataset: {len(df)} records\")\n",
    "# print(f\"Cleaned dataset: {len(df_clean)} records\")\n",
    "# print(f\"Removed: {len(df) - len(df_clean)} records ({((len(df) - len(df_clean))/len(df)*100):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Exploratory Data Analysis\n",
    "\n",
    "Add narrative about what you're exploring, why and what you've found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Most common complaint types\n",
    "# complaint_counts = df_clean'complaint_type'.value_counts().head(15)\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# complaint_counts.plot(kind='barh')\n",
    "# plt.xlabel('Number of Requests')\n",
    "# plt.ylabel('Complaint Type')\n",
    "# plt.title('Top 15 Most Common 311 Complaint Types')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Temporal patterns\n",
    "# requests_by_month = df_clean.groupby('month').size()\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# requests_by_month.plot(kind='bar')\n",
    "# plt.xlabel('Month')\n",
    "# plt.ylabel('Number of Requests')\n",
    "# plt.title('311 Requests by Month')\n",
    "# plt.xticks(rotation=0)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Research Question Analysis\n",
    "\n",
    "This is the core of your assignment. Document your analytical approach here. You can add any cells if you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your focused analysis goes here\n",
    "# This will vary significantly based on your research question. You can organize your analysis as you like. You can have as many cells as you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Testing (if applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Statistical tests\n",
    "# from scipy import stats\n",
    "\n",
    "# # t-test example\n",
    "# group1 = df_cleandf_clean'borough' == 'MANHATTAN''response_time_hours'.dropna()\n",
    "# group2 = df_cleandf_clean'borough' == 'BRONX''response_time_hours'.dropna()\n",
    "# t_stat, p_value = stats.ttest_ind(group1, group2)\n",
    "# print(f\"t-statistic: {t_stat:.3f}\")\n",
    "# print(f\"p-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Visualizations\n",
    "\n",
    "Create at least 3 polished visualizations that answer your research question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of Visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of Visualization 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Summary\n",
    "\n",
    "Summarize your key findings here. What patterns did you discover? What can you conclude?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question and Motivation\n",
    "\n",
    "- Why is this question interesting? \n",
    "- What might we learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods\n",
    "\n",
    "Describe your data source, cleaning steps, and analytical approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings\n",
    "\n",
    "Summarize key patterns and statistical results (refer to your key visualizations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "\n",
    "Discuss methodological limitations. What are the potential biases in 311 data? What alternative explanations exist for your findings? What can and cannot be concluded from this analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethical Considerations\n",
    "\n",
    "Reflect on the ethical implications of using 311 data:\n",
    "- Who is represented in this data? Who might be underrepresented?\n",
    "- What are potential privacy concerns?\n",
    "- How might this analysis be used or misused?\n",
    "- What are the implications for equity and justice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Appendix (if applicable)\n",
    "\n",
    "If you used AI during this assignnment, explain\n",
    "1. what part of the work it was used for; \n",
    "2. what AI tools you used; \n",
    "3. the prompts you used; \n",
    "4. how you analyzed the AI work for accuracy; and, \n",
    "5. steps you took to rework and revise your final documents so that they were both factually accurate and reflected your own voice and style.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Submit your assignment as .ipynb file. Make sure to double check with the assignment instructions on Canvas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
