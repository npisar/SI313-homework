{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readymade Data Module Assignment\n",
    "## NYC 311 Service Request Analysis\n",
    "\n",
    "**Student Name:** Nick Pisarczyk\n",
    "\n",
    "**U-M Unique Name:** npisar\n",
    "\n",
    "**Research Question:** State your chosen research question here\n",
    "\n",
    "---\n",
    "\n",
    "**BEFORE YOU START:**\n",
    "1. Read the assignment instructions on Canvas carefully.\n",
    "2. Make a copy of this notebook and work on your own copy.\n",
    "3. Understand the dataset before you start cleaning and analyzing. NYC Open Data has a nice portal and a data dictionary for exploring their datasets.\n",
    "4. NYC 311 is a **very large** dataset. When you are fetching data from the portal or API, we would recommend you to first think about your research questions and start with a small subset of the data and then increase the size of the data as you get more comfortable with the data. Generally, you do **not** need to use the entire dataset to answer your research question.\n",
    "5. This notebook serves as a template. You can add more cells or make adjustments as you see fit. But make sure to keep all the sections mentioned in the assignment instructions. Also, format your notebook properly for better readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Statement\n",
    "\n",
    "Describe your data source here. Include:\n",
    "- Where you obtained the data (URL or API endpoint)\n",
    "- What subset you're analyzing (dates, geography, etc.)\n",
    "- Any filters or sampling you applied\n",
    "- File size/number of records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Details (Canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://umich.instructure.com/courses/825993/assignments/3016485\n",
    "\n",
    "**Overview**\n",
    "This assignment asks you to analyze NYC 311 service request data to understand patterns in urban neighborhoods. You will use Python to explore relationships between service requests and socioeconomic characteristics, practicing skills in data cleaning, exploratory analysis, visualization, and interpretation.\n",
    "\n",
    "311 systems allow residents to report non-emergency issues like noise complaints, street conditions, and building problems. As Wang et al. (2017) demonstrated, these service request patterns can reveal distinctive “signatures” of urban neighborhoods that correlate with demographic and economic characteristics.\n",
    "\n",
    "---\n",
    "\n",
    "**Learning Objectives**<br>\n",
    "By completing this assignment, you will:<br>\n",
    "- Practice working with “readymade” administrative data from government sources\n",
    "- Develop skills in data cleaning and exploratory data analysis\n",
    "- Apply statistical methods to understand relationships in observational data\n",
    "- Create effective visualizations to communicate data patterns\n",
    "- Consider methodological limitations and ethical implications of using administrative data for research\n",
    "- Data\n",
    "\n",
    "---\n",
    "\n",
    "**NYC Open Data - 311 Service Requests**\n",
    "\n",
    "You will use NYC’s publicly available 311 service request dataLinks to an external site..\n",
    "\n",
    "Recommended approach: Explore the dataset using the NYC Open Data online portal and the data dictionary. The full dataset is very large (40+ million records), so filtering is essential. For instance, one year of data was around 2.6 GB. \n",
    "\n",
    "Based on your research question, identify an appropriate subset of the data (e.g., one year of data for specific boroughs or zip codes), and use the Socrata API or directly download it.You can find more information about the API and the documentation on NYC Open Data website.\n",
    "\n",
    "---\n",
    "\n",
    "**Research Questions**\n",
    "Choose ONE of the following research questions to investigate:\n",
    "\n",
    "- Option 1: Neighborhood Service Request Signatures\n",
    "<br>Do different neighborhoods have distinctive patterns in their 311 service requests? Analyze the relative frequency of complaint types across neighborhoods. What patterns do you notice?\n",
    "\n",
    "- Option 2: Temporal Patterns in Service Requests\n",
    "<br>How do 311 service requests vary by time of day, day of week, or season? Are there particular complaint types that show strong temporal patterns? What might explain these patterns?\n",
    "\n",
    "- Option 3: Response Time Disparities\n",
    "<br>Do response times for 311 requests differ across neighborhoods or complaint types? Calculate the time between request creation and closure, and examine whether there are systematic differences by location or complaint category.\n",
    "\n",
    "- Option 4: Complaint Type Evolution\n",
    "<br>How have the types and volumes of 311 requests changed over time (comparing multiple years)? What might explain these patterns?\n",
    "\n",
    "---\n",
    "\n",
    "**Assignment Requirements**<br>\n",
    "Your submission should include two components. Both should be included in a single Jupyter Notebook.\n",
    "<br>\n",
    "1. Data Analysis<br>\n",
    "Your notebook should include:\n",
    "\n",
    "- Data loading and initial exploration: Load the data, explain how you retrieve the data, why you choose the specific subset, examine its structure, and identify relevant variables\n",
    "- Data cleaning: Handle missing values, filter to relevant records, create derived variables as needed\n",
    "- Exploratory analysis: Use descriptive statistics and visualizations to understand patterns\n",
    "- Focused analysis: Apply appropriate statistical methods to address your research question\n",
    "- Visualizations: Create at least 3 meaningful visualizations (e.g., time series, bar charts, heatmaps, scatter plots)\n",
    "- Documentation: Include markdown cells explaining your approach, interpreting results, and noting limitations\n",
    "- Technical expectations: Use numpy/pandas for data manipulation, matplotlib/seaborn for visualization, and appropriate statistical libraries (scipy, statsmodels, etc.) as needed.\n",
    "\n",
    "2. Written Summary<br>\n",
    "Briefly report on the following. Your notebook should have a section for each bullet point.\n",
    "\n",
    "- Research question and motivation: What is your research question? Why is this question interesting? What might we learn?\n",
    "- Methods: Describe your data source, cleaning steps, and analytical approach\n",
    "- Findings: Summarize key patterns and statistical results (include 2-3 key visualizations)\n",
    "- Limitations: What are the methodological limitations? What can and cannot be concluded from this analysis?\n",
    "- Ethical considerations: Reflect on the use of 311 data for research. Who is represented? Who might be excluded? What are potential concerns about using this data?\n",
    " \n",
    "---\n",
    "\n",
    "**Assignment Submission**\n",
    "\n",
    "Please upload your Jupyter Notebook file to Canvas by the deadline: A single .ipynb file that includes all your work. \n",
    "\n",
    "Before submitting the file, ensure that your notebook is properly running on your machine. Ensure your notebook contains all your responses, plots, all programming parts of this assignment and is properly formatted with headings, explanations and code comments.\n",
    "\n",
    "If you use Generative AI tools in any part of your assignment, you need to follow the AI policy in our syllabus and document your AI use at the end of your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# You can import any libraries you may need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sodapy import Socrata\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv helper function\n",
    "def df_to_csv(d):\n",
    "    for borough, df in d.items():\n",
    "        df.to_csv(f\"../data/readymade_module_data/{borough}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper f for print output\n",
    "def spacer_top(i=50):\n",
    "    print(f\"{'='*i}\")\n",
    "    print(f\"{'='*i}\")\n",
    "\n",
    "def spacer_bottom(i=50):\n",
    "    print(f\"{'='*i}\")\n",
    "    print(f\"{'='*i}\")\n",
    "    print(f\"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A: Load from downloaded CSV file\n",
    "\n",
    "**Note**: If you are running the notebook using `colab` kernel, you **cannot** directly import the data from your own laptop. Please see the class repo README files for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfs keys is dict_keys(['bronx', 'brooklyn', 'manhattan', 'queens', 'staten island'])\n"
     ]
    }
   ],
   "source": [
    "# Load your downloaded data\n",
    "\n",
    "# df setup\n",
    "# define the 5 NYC boroughs (neighborhoods)\n",
    "boroughs = [\n",
    "    \"BRONX\",\n",
    "    \"BROOKLYN\",\n",
    "    \"MANHATTAN\",\n",
    "    \"QUEENS\",\n",
    "    \"STATEN ISLAND\"\n",
    "]\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "# add each to dict\n",
    "for borough in boroughs:\n",
    "    dfs[borough.lower()] = pd.read_csv(f'../data/readymade_module_data/{borough.lower()}.csv', \n",
    "                    low_memory=False)\n",
    "print(f\"dfs keys is {dfs.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Load from Socrata API (recommended for smaller datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nShould only have to do this once. Created this code to gather data with the columns I wanted, and then saved them to CSVs for easy access.\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Should only have to do this once. Created this code to gather data with the columns I wanted, and then saved them to CSVs for easy access.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# # Example: Get 100,000 records from 2023 for Brooklyn\n",
    "# client = Socrata(\"data.cityofnewyork.us\", None)\n",
    "# client.timeout = 60\n",
    "\n",
    "# # specify columns to reduce runtimes and get only pertinent data\n",
    "# columns = [\n",
    "#     \"unique_key\",\n",
    "#     \"created_date\",\n",
    "#     \"closed_date\",\n",
    "#     \"complaint_type\",\n",
    "#     \"descriptor\",\n",
    "#     \"descriptor_2\",\n",
    "#     \"borough\"\n",
    "# ]\n",
    "# select_str = ', '.join(columns)\n",
    "\n",
    "# # df setup\n",
    "# # define the 5 NYC boroughs (neighborhoods)\n",
    "# boroughs = [\n",
    "#     \"BRONX\",\n",
    "#     \"BROOKLYN\",\n",
    "#     \"MANHATTAN\",\n",
    "#     \"QUEENS\",\n",
    "#     \"STATEN ISLAND\"\n",
    "# ]\n",
    "\n",
    "# dfs = {}\n",
    "\n",
    "# # find data for each borough and create 5 separate dfs\n",
    "# for borough in boroughs:\n",
    "#     print(f\"Gathering data for borough: {borough}...\")\n",
    "#     results = client.get(\"erm2-nwe9\", \n",
    "#                         select=select_str,\n",
    "#                         where=f\"created_date >= '2026-01-01' AND borough = '{borough}'\",\n",
    "#                         limit=100000)\n",
    "#     dfs[borough.lower()] = pd.DataFrame.from_records(results)\n",
    "\n",
    "#     print(f\"Converting time columns...\")\n",
    "#     # Convert date columns\n",
    "#     dfs[borough.lower()]['created_date'] = pd.to_datetime(dfs[borough.lower()]['created_date'])\n",
    "#     dfs[borough.lower()]['closed_date'] = pd.to_datetime(dfs[borough.lower()]['closed_date'])\n",
    "\n",
    "#     if not borough == \"STATEN ISLAND\":\n",
    "#         print(f\"Complete! Next bourough...\\n\\n\")\n",
    "#     else:\n",
    "#         print(f\"Complete for all boroughs!\")\n",
    "    \n",
    "# print(f\"dfs dict is:\\n{dfs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLike last cell, should only have to do this once. Created this code to save gathered data to CSVs for easy access, not needed once CSVs already on machine.\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Like last cell, should only have to do this once. Created this code to save gathered data to CSVs for easy access, not needed once CSVs already on machine.\n",
    "\"\"\"\n",
    "\n",
    "# # save to CSV for easier access\n",
    "# df_to_csv(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Data Description\n",
    "\n",
    "You can describe the data in many ways. Here are some baseline requirements:\n",
    "- Display basic information about the dataset (what are the relevant variables? What are their types? How many observations are there?)\n",
    "- Conduct summary statistics of the relevant variables\n",
    "- Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "===========================================================================\n",
      "BRONX DATA HEAD\n",
      "  unique_key        created_date          complaint_type        descriptor  \\\n",
      "0   67517646 2026-01-16 15:35:05           PAINT/PLASTER      WINDOW/FRAME   \n",
      "1   67353979 2026-01-01 22:57:00  Street Light Condition  Street Light Out   \n",
      "2   67369613 2026-01-02 08:46:05    UNSANITARY CONDITION             PESTS   \n",
      "3   67373383 2026-01-03 18:41:56                 GENERAL       COOKING GAS   \n",
      "4   67373683 2026-01-03 18:41:56                PLUMBING        BASIN/SINK   \n",
      "\n",
      "                  descriptor_2 borough         closed_date  \n",
      "0     PEELING OR FLAKING PAINT   BRONX                 NaT  \n",
      "1  Location Type: Intersection   BRONX 2026-01-06 09:12:00  \n",
      "2                        OTHER   BRONX 2026-02-02 09:52:00  \n",
      "3                     SHUT-OFF   BRONX 2026-01-26 09:32:02  \n",
      "4      SINK DETACHED FROM WALL   BRONX 2026-01-26 09:32:02  \n",
      "===========================================================================\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "===========================================================================\n",
      "===========================================================================\n",
      "BROOKLYN DATA HEAD\n",
      "  unique_key        created_date         closed_date  complaint_type  \\\n",
      "0   67392685 2026-01-05 23:57:47 2026-01-09 02:04:24  HEAT/HOT WATER   \n",
      "1   67654110 2026-01-28 11:42:23 2026-01-28 19:25:07  HEAT/HOT WATER   \n",
      "2   67654127 2026-01-28 17:52:48                 NaT   PAINT/PLASTER   \n",
      "3   67654149 2026-01-28 11:57:53 2026-01-28 20:34:28   PAINT/PLASTER   \n",
      "4   67654153 2026-01-28 01:55:18                 NaT   PAINT/PLASTER   \n",
      "\n",
      "        descriptor             descriptor_2   borough  \n",
      "0  ENTIRE BUILDING                  NO HEAT  BROOKLYN  \n",
      "1  ENTIRE BUILDING             NO HOT WATER  BROOKLYN  \n",
      "2          CEILING  CHIPPED/PEELING/FLAKING  BROOKLYN  \n",
      "3             WALL  CHIPPED/PEELING/FLAKING  BROOKLYN  \n",
      "4             WALL  CHIPPED/PEELING/FLAKING  BROOKLYN  \n",
      "===========================================================================\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "===========================================================================\n",
      "===========================================================================\n",
      "MANHATTAN DATA HEAD\n",
      "  unique_key        created_date         closed_date  \\\n",
      "0   67654102 2026-01-28 07:16:46 2026-01-29 10:10:59   \n",
      "1   67654160 2026-01-28 12:08:06                 NaT   \n",
      "2   67371129 2026-01-02 10:32:41 2026-01-14 00:00:00   \n",
      "3   67371686 2026-01-02 14:50:17 2026-01-15 00:00:00   \n",
      "4   67377584 2026-01-03 16:57:09 2026-01-14 00:00:00   \n",
      "\n",
      "                            complaint_type  \\\n",
      "0                           HEAT/HOT WATER   \n",
      "1                                 PLUMBING   \n",
      "2                                 Elevator   \n",
      "3  Special Projects Inspection Team (SPIT)   \n",
      "4                             Building/Use   \n",
      "\n",
      "                                          descriptor  \\\n",
      "0                                    ENTIRE BUILDING   \n",
      "1                                         BASIN/SINK   \n",
      "2  Elevator - Single Device On Property/No Altern...   \n",
      "3        Illegal Hotel Rooms In Residential Building   \n",
      "4   Illegal Conversion Of Residential Building/Space   \n",
      "\n",
      "               descriptor_2    borough  \n",
      "0  NO HEAT AND NO HOT WATER  MANHATTAN  \n",
      "1   BASIN CHIPPED OR RUSTED  MANHATTAN  \n",
      "2                       NaN  MANHATTAN  \n",
      "3                       NaN  MANHATTAN  \n",
      "4                       NaN  MANHATTAN  \n",
      "===========================================================================\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "===========================================================================\n",
      "===========================================================================\n",
      "QUEENS DATA HEAD\n",
      "  unique_key        created_date         closed_date  \\\n",
      "0   67346584 2026-01-01 01:42:08 2026-02-01 04:00:59   \n",
      "1   67353898 2026-01-01 01:12:35 2026-01-23 00:00:00   \n",
      "2   67372955 2026-01-03 04:22:13 2026-01-13 00:00:00   \n",
      "3   67373670 2026-01-03 22:36:32 2026-01-30 06:54:53   \n",
      "4   67373891 2026-01-03 13:24:00 2026-01-03 20:21:00   \n",
      "\n",
      "                  complaint_type               descriptor     descriptor_2  \\\n",
      "0             Consumer Complaint        Tow Truck Company   Vehicle Damage   \n",
      "1  General Construction/Plumbing  Fence - None/Inadequate              NaN   \n",
      "2  General Construction/Plumbing   Building Permit - None              NaN   \n",
      "3                  PAINT/PLASTER                  CEILING  HOLE OR CRACKED   \n",
      "4              Derelict Vehicles        Derelict Vehicles              NaN   \n",
      "\n",
      "  borough  \n",
      "0  QUEENS  \n",
      "1  QUEENS  \n",
      "2  QUEENS  \n",
      "3  QUEENS  \n",
      "4  QUEENS  \n",
      "===========================================================================\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "===========================================================================\n",
      "===========================================================================\n",
      "STATEN ISLAND DATA HEAD\n",
      "  unique_key        created_date         closed_date  \\\n",
      "0   67364698 2026-01-02 21:35:00 2026-01-12 13:53:00   \n",
      "1   67445587 2026-01-09 14:35:12 2026-01-12 00:00:00   \n",
      "2   67448960 2026-01-10 16:49:11 2026-01-12 00:00:00   \n",
      "3   67465943 2026-01-12 12:05:50 2026-01-12 14:02:57   \n",
      "4   67469065 2026-01-10 23:00:00 2026-01-12 12:31:00   \n",
      "\n",
      "                  complaint_type                        descriptor  \\\n",
      "0         Street Light Condition                  Street Light Out   \n",
      "1  General Construction/Plumbing           Fence - None/Inadequate   \n",
      "2  General Construction/Plumbing           Fence - None/Inadequate   \n",
      "3                           Mold  Public Complaint - Comm Location   \n",
      "4              Derelict Vehicles                 Derelict Vehicles   \n",
      "\n",
      "                  descriptor_2        borough  \n",
      "0  Location Type: Intersection  STATEN ISLAND  \n",
      "1                          NaN  STATEN ISLAND  \n",
      "2                          NaN  STATEN ISLAND  \n",
      "3                          NaN  STATEN ISLAND  \n",
      "4                          NaN  STATEN ISLAND  \n",
      "===========================================================================\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can have as many cells as you want\n",
    "for borough, df in dfs.items():\n",
    "    spacer_top(75)\n",
    "    \n",
    "    print(f\"{borough.upper()} DATA HEAD\")\n",
    "    print(df.head())\n",
    "    \n",
    "    spacer_bottom(75)\n",
    "\n",
    "### NEED TO DESCRIBE DATA MORE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning\n",
    "\n",
    "Document your cleaning decisions and rationale here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example cleaning steps (customize based on your needs)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 1. Remove rows with missing essential data\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# df_clean'day_of_week' = df_clean'created_date'.dt.dayofweek\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# df_clean'month' = df_clean'created_date'.dt.month\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m records\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Example cleaning steps (customize based on your needs)\n",
    "\n",
    "# 1. Remove rows with missing essential data\n",
    "# df_clean = df.dropna(subset='created_date', 'complaint_type')\n",
    "\n",
    "# 2. Filter to specific time period if needed\n",
    "# df_clean = df_clean(df_clean'created_date' >= '2023-01-01') & \n",
    "#                     (df_clean'created_date' < '2024-01-01')\n",
    "\n",
    "# 3. Create derived variables\n",
    "# Example: Calculate response time\n",
    "# df_clean'response_time_hours' = (\n",
    "#     (df_clean'closed_date' - df_clean'created_date').dt.total_seconds() / 3600\n",
    "# )\n",
    "\n",
    "# Example: Extract temporal features\n",
    "# df_clean'hour' = df_clean'created_date'.dt.hour\n",
    "# df_clean'day_of_week' = df_clean'created_date'.dt.dayofweek\n",
    "# df_clean'month' = df_clean'created_date'.dt.month\n",
    "\n",
    "print(f\"Original dataset: {len(df)} records\")\n",
    "# print(f\"Cleaned dataset: {len(df_clean)} records\")\n",
    "# print(f\"Removed: {len(df) - len(df_clean)} records ({((len(df) - len(df_clean))/len(df)*100):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Exploratory Data Analysis\n",
    "\n",
    "Add narrative about what you're exploring, why and what you've found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Most common complaint types\n",
    "# complaint_counts = df_clean'complaint_type'.value_counts().head(15)\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# complaint_counts.plot(kind='barh')\n",
    "# plt.xlabel('Number of Requests')\n",
    "# plt.ylabel('Complaint Type')\n",
    "# plt.title('Top 15 Most Common 311 Complaint Types')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Temporal patterns\n",
    "# requests_by_month = df_clean.groupby('month').size()\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# requests_by_month.plot(kind='bar')\n",
    "# plt.xlabel('Month')\n",
    "# plt.ylabel('Number of Requests')\n",
    "# plt.title('311 Requests by Month')\n",
    "# plt.xticks(rotation=0)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Research Question Analysis\n",
    "\n",
    "This is the core of your assignment. Document your analytical approach here. You can add any cells if you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your focused analysis goes here\n",
    "# This will vary significantly based on your research question. You can organize your analysis as you like. You can have as many cells as you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Testing (if applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Statistical tests\n",
    "# from scipy import stats\n",
    "\n",
    "# # t-test example\n",
    "# group1 = df_cleandf_clean'borough' == 'MANHATTAN''response_time_hours'.dropna()\n",
    "# group2 = df_cleandf_clean'borough' == 'BRONX''response_time_hours'.dropna()\n",
    "# t_stat, p_value = stats.ttest_ind(group1, group2)\n",
    "# print(f\"t-statistic: {t_stat:.3f}\")\n",
    "# print(f\"p-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Visualizations\n",
    "\n",
    "Create at least 3 polished visualizations that answer your research question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of Visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of Visualization 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Summary\n",
    "\n",
    "Summarize your key findings here. What patterns did you discover? What can you conclude?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question and Motivation\n",
    "\n",
    "- Why is this question interesting? \n",
    "- What might we learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods\n",
    "\n",
    "Describe your data source, cleaning steps, and analytical approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings\n",
    "\n",
    "Summarize key patterns and statistical results (refer to your key visualizations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "\n",
    "Discuss methodological limitations. What are the potential biases in 311 data? What alternative explanations exist for your findings? What can and cannot be concluded from this analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethical Considerations\n",
    "\n",
    "Reflect on the ethical implications of using 311 data:\n",
    "- Who is represented in this data? Who might be underrepresented?\n",
    "- What are potential privacy concerns?\n",
    "- How might this analysis be used or misused?\n",
    "- What are the implications for equity and justice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Appendix (if applicable)\n",
    "\n",
    "If you used AI during this assignnment, explain\n",
    "1. what part of the work it was used for; \n",
    "2. what AI tools you used; \n",
    "3. the prompts you used; \n",
    "4. how you analyzed the AI work for accuracy; and, \n",
    "5. steps you took to rework and revise your final documents so that they were both factually accurate and reflected your own voice and style.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Submit your assignment as .ipynb file. Make sure to double check with the assignment instructions on Canvas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
