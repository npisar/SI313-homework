{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readymade Data Module Assignment\n",
    "## NYC 311 Service Request Analysis\n",
    "\n",
    "**Student Name:** Nick Pisarczyk\n",
    "\n",
    "**U-M Unique Name:** npisar\n",
    "\n",
    "**Research Question:** State your chosen research question here\n",
    "\n",
    "---\n",
    "\n",
    "**BEFORE YOU START:**\n",
    "1. Read the assignment instructions on Canvas carefully.\n",
    "2. Make a copy of this notebook and work on your own copy.\n",
    "3. Understand the dataset before you start cleaning and analyzing. NYC Open Data has a nice portal and a data dictionary for exploring their datasets.\n",
    "4. NYC 311 is a **very large** dataset. When you are fetching data from the portal or API, we would recommend you to first think about your research questions and start with a small subset of the data and then increase the size of the data as you get more comfortable with the data. Generally, you do **not** need to use the entire dataset to answer your research question.\n",
    "5. This notebook serves as a template. You can add more cells or make adjustments as you see fit. But make sure to keep all the sections mentioned in the assignment instructions. Also, format your notebook properly for better readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Statement\n",
    "\n",
    "Describe your data source here. Include:\n",
    "- Where you obtained the data (URL or API endpoint)\n",
    "- What subset you're analyzing (dates, geography, etc.)\n",
    "- Any filters or sampling you applied\n",
    "- File size/number of records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Details (Canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://umich.instructure.com/courses/825993/assignments/3016485\n",
    "\n",
    "Overview\n",
    "This assignment asks you to analyze NYC 311 service request data to understand patterns in urban neighborhoods. You will use Python to explore relationships between service requests and socioeconomic characteristics, practicing skills in data cleaning, exploratory analysis, visualization, and interpretation.\n",
    "\n",
    "311 systems allow residents to report non-emergency issues like noise complaints, street conditions, and building problems. As Wang et al. (2017) demonstrated, these service request patterns can reveal distinctive “signatures” of urban neighborhoods that correlate with demographic and economic characteristics.\n",
    "\n",
    "Learning Objectives\n",
    "By completing this assignment, you will:\n",
    "\n",
    "Practice working with “readymade” administrative data from government sources\n",
    "Develop skills in data cleaning and exploratory data analysis\n",
    "Apply statistical methods to understand relationships in observational data\n",
    "Create effective visualizations to communicate data patterns\n",
    "Consider methodological limitations and ethical implications of using administrative data for research\n",
    "Data\n",
    "NYC Open Data - 311 Service Requests\n",
    "\n",
    "You will use NYC’s publicly available 311 service request dataLinks to an external site..\n",
    "\n",
    "Recommended approach: Explore the dataset using the NYC Open Data online portal and the data dictionary. The full dataset is very large (40+ million records), so filtering is essential. For instance, one year of data was around 2.6 GB. \n",
    "\n",
    "Based on your research question, identify an appropriate subset of the data (e.g., one year of data for specific boroughs or zip codes), and use the Socrata API or directly download it.You can find more information about the API and the documentation on NYC Open Data website.\n",
    "\n",
    "Research Questions\n",
    "Choose ONE of the following research questions to investigate:\n",
    "\n",
    "Option 1: Neighborhood Service Request Signatures\n",
    "Do different neighborhoods have distinctive patterns in their 311 service requests? Analyze the relative frequency of complaint types across neighborhoods. What patterns do you notice?\n",
    "\n",
    "Option 2: Temporal Patterns in Service Requests\n",
    "How do 311 service requests vary by time of day, day of week, or season? Are there particular complaint types that show strong temporal patterns? What might explain these patterns?\n",
    "\n",
    "Option 3: Response Time Disparities\n",
    "Do response times for 311 requests differ across neighborhoods or complaint types? Calculate the time between request creation and closure, and examine whether there are systematic differences by location or complaint category.\n",
    "\n",
    "Option 4: Complaint Type Evolution\n",
    "How have the types and volumes of 311 requests changed over time (comparing multiple years)? What might explain these patterns?\n",
    "\n",
    "Assignment Requirements\n",
    "Your submission should include two components. Both should be included in a single Jupyter Notebook.\n",
    "\n",
    "1. Data Analysis\n",
    "Your notebook should include:\n",
    "\n",
    "Data loading and initial exploration: Load the data, explain how you retrieve the data, why you choose the specific subset, examine its structure, and identify relevant variables\n",
    "Data cleaning: Handle missing values, filter to relevant records, create derived variables as needed\n",
    "Exploratory analysis: Use descriptive statistics and visualizations to understand patterns\n",
    "Focused analysis: Apply appropriate statistical methods to address your research question\n",
    "Visualizations: Create at least 3 meaningful visualizations (e.g., time series, bar charts, heatmaps, scatter plots)\n",
    "Documentation: Include markdown cells explaining your approach, interpreting results, and noting limitations\n",
    "Technical expectations: Use numpy/pandas for data manipulation, matplotlib/seaborn for visualization, and appropriate statistical libraries (scipy, statsmodels, etc.) as needed.\n",
    "\n",
    "2. Written Summary\n",
    "Briefly report on the following. Your notebook should have a section for each bullet point.\n",
    "\n",
    "Research question and motivation: What is your research question? Why is this question interesting? What might we learn?\n",
    "Methods: Describe your data source, cleaning steps, and analytical approach\n",
    "Findings: Summarize key patterns and statistical results (include 2-3 key visualizations)\n",
    "Limitations: What are the methodological limitations? What can and cannot be concluded from this analysis?\n",
    "Ethical considerations: Reflect on the use of 311 data for research. Who is represented? Who might be excluded? What are potential concerns about using this data?\n",
    " \n",
    "\n",
    "Assignment Submission\n",
    "\n",
    "Please upload your Jupyter Notebook file to Canvas by the deadline: A single .ipynb file that includes all your work. \n",
    "\n",
    "Before submitting the file, ensure that your notebook is properly running on your machine. Ensure your notebook contains all your responses, plots, all programming parts of this assignment and is properly formatted with headings, explanations and code comments.\n",
    "\n",
    "If you use Generative AI tools in any part of your assignment, you need to follow the AI policy in our syllabus and document your AI use at the end of your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# You can import any libraries you may need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams'figure.figsize' = (12, 6)\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A: Load from downloaded CSV file\n",
    "\n",
    "**Note**: If you are running the notebook using `colab` kernel, you **cannot** directly import the data from your own laptop. Please see the class repo README files for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your downloaded data\n",
    "# df = pd.read_csv('311_Service_Requests.csv', \n",
    "#                  parse_dates='Created Date', 'Closed Date',\n",
    "#                  low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Load from Socrata API (recommended for smaller datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install sodapy # UNCOMMENT THIS LINE IF YOU NEED TO INSTALL sodapy: \n",
    "\n",
    "# from sodapy import Socrata\n",
    "\n",
    "# # Example: Get 100,000 records from 2023 for Brooklyn\n",
    "# client = Socrata(\"data.cityofnewyork.us\", None)\n",
    "# results = client.get(\"erm2-nwe9\", \n",
    "#                      where=\"created_date >= '2023-01-01' AND borough = 'BROOKLYN'\",\n",
    "#                      limit=100000)\n",
    "# df = pd.DataFrame.from_records(results)\n",
    "\n",
    "# # Convert date columns\n",
    "# df'created_date' = pd.to_datetime(df'created_date')\n",
    "# df'closed_date' = pd.to_datetime(df'closed_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Data Description\n",
    "\n",
    "You can describe the data in many ways. Here are some baseline requirements:\n",
    "- Display basic information about the dataset (what are the relevant variables? What are their types? How many observations are there?)\n",
    "- Conduct summary statistics of the relevant variables\n",
    "- Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can have as many cells as you want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning\n",
    "\n",
    "Document your cleaning decisions and rationale here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example cleaning steps (customize based on your needs)\n",
    "\n",
    "# 1. Remove rows with missing essential data\n",
    "# df_clean = df.dropna(subset='created_date', 'complaint_type')\n",
    "\n",
    "# 2. Filter to specific time period if needed\n",
    "# df_clean = df_clean(df_clean'created_date' >= '2023-01-01') & \n",
    "#                     (df_clean'created_date' < '2024-01-01')\n",
    "\n",
    "# 3. Create derived variables\n",
    "# Example: Calculate response time\n",
    "# df_clean'response_time_hours' = (\n",
    "#     (df_clean'closed_date' - df_clean'created_date').dt.total_seconds() / 3600\n",
    "# )\n",
    "\n",
    "# Example: Extract temporal features\n",
    "# df_clean'hour' = df_clean'created_date'.dt.hour\n",
    "# df_clean'day_of_week' = df_clean'created_date'.dt.dayofweek\n",
    "# df_clean'month' = df_clean'created_date'.dt.month\n",
    "\n",
    "print(f\"Original dataset: {len(df)} records\")\n",
    "# print(f\"Cleaned dataset: {len(df_clean)} records\")\n",
    "# print(f\"Removed: {len(df) - len(df_clean)} records ({((len(df) - len(df_clean))/len(df)*100):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Exploratory Data Analysis\n",
    "\n",
    "Add narrative about what you're exploring, why and what you've found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Most common complaint types\n",
    "# complaint_counts = df_clean'complaint_type'.value_counts().head(15)\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# complaint_counts.plot(kind='barh')\n",
    "# plt.xlabel('Number of Requests')\n",
    "# plt.ylabel('Complaint Type')\n",
    "# plt.title('Top 15 Most Common 311 Complaint Types')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Temporal patterns\n",
    "# requests_by_month = df_clean.groupby('month').size()\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# requests_by_month.plot(kind='bar')\n",
    "# plt.xlabel('Month')\n",
    "# plt.ylabel('Number of Requests')\n",
    "# plt.title('311 Requests by Month')\n",
    "# plt.xticks(rotation=0)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Research Question Analysis\n",
    "\n",
    "This is the core of your assignment. Document your analytical approach here. You can add any cells if you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your focused analysis goes here\n",
    "# This will vary significantly based on your research question. You can organize your analysis as you like. You can have as many cells as you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Testing (if applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Statistical tests\n",
    "# from scipy import stats\n",
    "\n",
    "# # t-test example\n",
    "# group1 = df_cleandf_clean'borough' == 'MANHATTAN''response_time_hours'.dropna()\n",
    "# group2 = df_cleandf_clean'borough' == 'BRONX''response_time_hours'.dropna()\n",
    "# t_stat, p_value = stats.ttest_ind(group1, group2)\n",
    "# print(f\"t-statistic: {t_stat:.3f}\")\n",
    "# print(f\"p-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Visualizations\n",
    "\n",
    "Create at least 3 polished visualizations that answer your research question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of Visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of Visualization 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Summary\n",
    "\n",
    "Summarize your key findings here. What patterns did you discover? What can you conclude?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question and Motivation\n",
    "\n",
    "- Why is this question interesting? \n",
    "- What might we learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods\n",
    "\n",
    "Describe your data source, cleaning steps, and analytical approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings\n",
    "\n",
    "Summarize key patterns and statistical results (refer to your key visualizations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "\n",
    "Discuss methodological limitations. What are the potential biases in 311 data? What alternative explanations exist for your findings? What can and cannot be concluded from this analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethical Considerations\n",
    "\n",
    "Reflect on the ethical implications of using 311 data:\n",
    "- Who is represented in this data? Who might be underrepresented?\n",
    "- What are potential privacy concerns?\n",
    "- How might this analysis be used or misused?\n",
    "- What are the implications for equity and justice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Appendix (if applicable)\n",
    "\n",
    "If you used AI during this assignnment, explain\n",
    "1. what part of the work it was used for; \n",
    "2. what AI tools you used; \n",
    "3. the prompts you used; \n",
    "4. how you analyzed the AI work for accuracy; and, \n",
    "5. steps you took to rework and revise your final documents so that they were both factually accurate and reflected your own voice and style.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Submit your assignment as .ipynb file. Make sure to double check with the assignment instructions on Canvas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
