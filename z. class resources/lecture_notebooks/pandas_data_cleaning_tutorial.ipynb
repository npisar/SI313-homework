{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Data Cleaning and Manipulation Tutorial\n",
    "\n",
    "This notebook demonstrates essential `pandas` methods for data cleaning and manipulation. You are likely to use some of these methods in your assignments and projects.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Load and inspect data with pandas\n",
    "- Handle missing values\n",
    "- Filter and select data\n",
    "- Transform and create new columns\n",
    "- Group and aggregate data\n",
    "- Merge and combine datasets\n",
    "- Clean and standardize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_rows', 50)        # Show up to 50 rows\n",
    "pd.set_option('display.width', None)        # Auto-detect display width\n",
    "pd.set_option('display.max_colwidth', 50)   # Limit column width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Sample Data\n",
    "\n",
    "We'll create a sample dataset with various data quality issues to demonstrate cleaning techniques. **You don't need to change the code below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample dataset created!\n",
      "\n",
      "Dataset shape: (20, 8)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>grade</th>\n",
       "      <th>score</th>\n",
       "      <th>department</th>\n",
       "      <th>enrollment_date</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>20.0</td>\n",
       "      <td>A</td>\n",
       "      <td>95</td>\n",
       "      <td>CS</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>alice@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bob</td>\n",
       "      <td>21.0</td>\n",
       "      <td>B</td>\n",
       "      <td>85</td>\n",
       "      <td>Math</td>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>bob@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>92</td>\n",
       "      <td>CS</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>charlie@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Diana</td>\n",
       "      <td>19.0</td>\n",
       "      <td>C</td>\n",
       "      <td>72</td>\n",
       "      <td>Physics</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>diana@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Eve</td>\n",
       "      <td>22.0</td>\n",
       "      <td>B</td>\n",
       "      <td>88</td>\n",
       "      <td>Math</td>\n",
       "      <td>2023-02-15</td>\n",
       "      <td>eve@email.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   student_id         name   age grade  score department enrollment_date  \\\n",
       "0           1        Alice  20.0     A     95         CS      2023-01-15   \n",
       "1           2          Bob  21.0     B     85       Math      2023-01-20   \n",
       "2           3    Charlie     NaN     A     92         CS      2023-02-01   \n",
       "3           4        Diana  19.0     C     72    Physics      2023-01-10   \n",
       "4           5          Eve  22.0     B     88       Math      2023-02-15   \n",
       "\n",
       "               email  \n",
       "0    alice@email.com  \n",
       "1      bob@email.com  \n",
       "2  charlie@email.com  \n",
       "3    diana@email.com  \n",
       "4      eve@email.com  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample data with intentional issues for demonstration\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "data = {\n",
    "    'student_id': range(1, 21),\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank', 'Grace', 'Henry', \n",
    "             'Ivy', 'Jack', 'Kate', 'Liam', 'Mia', 'Noah', 'Olivia', 'Paul', \n",
    "             'Quinn', 'Rachel', 'Sam', 'Tina'],\n",
    "    'age': [20, 21, np.nan, 19, 22, 20, np.nan, 23, 21, 20, 19, 22, 20, 21, np.nan, 20, 21, 19, 22, 20],\n",
    "    'grade': ['A', 'B', 'A', 'C', 'B', 'A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'A', 'C', 'B', 'A', 'B', 'C', 'A'],\n",
    "    'score': [95, 85, 92, 72, 88, 90, 87, 75, 94, 82, 70, 93, 86, 91, 68, 84, 96, 83, 73, 89],\n",
    "    'department': ['CS', 'Math', 'CS', 'Physics', 'Math', 'CS', 'Math', 'Physics', \n",
    "                   'CS', 'Math', 'Physics', 'CS', 'Math', 'CS', 'Physics', 'Math', \n",
    "                   'CS', 'Math', 'Physics', 'CS'],\n",
    "    'enrollment_date': ['2023-01-15', '2023-01-20', '2023-02-01', '2023-01-10', '2023-02-15',\n",
    "                        '2023-01-05', '2023-02-10', '2023-01-25', '2023-02-05', '2023-01-30',\n",
    "                        '2023-02-20', '2023-01-12', '2023-02-08', '2023-01-18', '2023-02-12',\n",
    "                        '2023-01-22', '2023-02-03', '2023-01-28', '2023-02-18', '2023-01-08'],\n",
    "    'email': ['alice@email.com', 'bob@email.com', 'charlie@email.com', 'diana@email.com',\n",
    "              'eve@email.com', 'frank@email.com', 'grace@email.com', 'henry@email.com',\n",
    "              'ivy@email.com', 'jack@email.com', 'kate@email.com', 'liam@email.com',\n",
    "              'mia@email.com', 'noah@email.com', 'olivia@email.com', 'paul@email.com',\n",
    "              'quinn@email.com', 'rachel@email.com', 'sam@email.com', 'tina@email.com']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Introduce some data quality issues\n",
    "df.loc[2, 'name'] = '  Charlie  '  # Extra whitespace\n",
    "df.loc[5, 'grade'] = 'a'  # Lowercase inconsistency\n",
    "df.loc[8, 'department'] = 'cs'  # Lowercase inconsistency\n",
    "df.loc[12, 'score'] = 150  # Outlier (impossible score)\n",
    "df.loc[15, 'email'] = 'invalid-email'  # Invalid email format\n",
    "\n",
    "print(\"Sample dataset created!\")\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Inspection Methods\n",
    "\n",
    "Before cleaning, it's crucial to understand your data. Here are essential inspection methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 `df.info()` - Get DataFrame Information\n",
    "\n",
    "**What it does:** Provides a concise summary of the DataFrame including:\n",
    "- Number of non-null values in each column\n",
    "- Data types of each column\n",
    "- Memory usage\n",
    "\n",
    "**When to use:** First step after loading data to understand structure and identify missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   student_id       20 non-null     int64  \n",
      " 1   name             20 non-null     object \n",
      " 2   age              17 non-null     float64\n",
      " 3   grade            20 non-null     object \n",
      " 4   score            20 non-null     int64  \n",
      " 5   department       20 non-null     object \n",
      " 6   enrollment_date  20 non-null     object \n",
      " 7   email            20 non-null     object \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 1.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display DataFrame information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 `df.describe()` - Statistical Summary\n",
    "\n",
    "**What it does:** Generates descriptive statistics for numeric columns:\n",
    "- Count, mean, standard deviation\n",
    "- Min, max, quartiles (25%, 50%, 75%)\n",
    "\n",
    "**When to use:** To understand the distribution of numeric variables and identify potential outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>age</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.00000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.50000</td>\n",
       "      <td>20.588235</td>\n",
       "      <td>87.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.91608</td>\n",
       "      <td>1.175735</td>\n",
       "      <td>17.027146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.75000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>80.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.50000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>87.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.25000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>92.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.00000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       student_id        age       score\n",
       "count    20.00000  17.000000   20.000000\n",
       "mean     10.50000  20.588235   87.850000\n",
       "std       5.91608   1.175735   17.027146\n",
       "min       1.00000  19.000000   68.000000\n",
       "25%       5.75000  20.000000   80.250000\n",
       "50%      10.50000  20.000000   87.500000\n",
       "75%      15.25000  21.000000   92.250000\n",
       "max      20.00000  23.000000  150.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistical summary for numeric columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 `df.head()` and `df.tail()` - View First/Last Rows\n",
    "\n",
    "**What it does:** \n",
    "- `head(n)`: Returns first n rows (default: 5)\n",
    "- `tail(n)`: Returns last n rows (default: 5)\n",
    "\n",
    "**When to use:** Quick visual inspection of data structure and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n",
      "   student_id         name   age grade  score department enrollment_date  \\\n",
      "0           1        Alice  20.0     A     95         CS      2023-01-15   \n",
      "1           2          Bob  21.0     B     85       Math      2023-01-20   \n",
      "2           3    Charlie     NaN     A     92         CS      2023-02-01   \n",
      "3           4        Diana  19.0     C     72    Physics      2023-01-10   \n",
      "4           5          Eve  22.0     B     88       Math      2023-02-15   \n",
      "\n",
      "               email  \n",
      "0    alice@email.com  \n",
      "1      bob@email.com  \n",
      "2  charlie@email.com  \n",
      "3    diana@email.com  \n",
      "4      eve@email.com  \n",
      "\n",
      "==================================================\n",
      "\n",
      "Last 5 rows:\n",
      "    student_id    name   age grade  score department enrollment_date  \\\n",
      "15          16    Paul  20.0     B     84       Math      2023-01-22   \n",
      "16          17   Quinn  21.0     A     96         CS      2023-02-03   \n",
      "17          18  Rachel  19.0     B     83       Math      2023-01-28   \n",
      "18          19     Sam  22.0     C     73    Physics      2023-02-18   \n",
      "19          20    Tina  20.0     A     89         CS      2023-01-08   \n",
      "\n",
      "               email  \n",
      "15     invalid-email  \n",
      "16   quinn@email.com  \n",
      "17  rachel@email.com  \n",
      "18     sam@email.com  \n",
      "19    tina@email.com  \n"
     ]
    }
   ],
   "source": [
    "# View first 5 rows\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# View last 5 rows\n",
    "print(\"Last 5 rows:\")\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 `df.isna()` - Check for Missing Values\n",
    "\n",
    "**What it does:** Returns a DataFrame of boolean values indicating missing data (True = missing, False = present).\n",
    "\n",
    "**Note:** `isna()` and `isnull()` are identical - use either one depending on your `pandas` version.\n",
    "\n",
    "**When to use:** To identify which cells contain missing values before deciding how to handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values check:\n",
      "   student_id   name    age  grade  score  department  enrollment_date  email\n",
      "0       False  False  False  False  False       False            False  False\n",
      "1       False  False  False  False  False       False            False  False\n",
      "2       False  False   True  False  False       False            False  False\n",
      "3       False  False  False  False  False       False            False  False\n",
      "4       False  False  False  False  False       False            False  False\n",
      "\n",
      "==================================================\n",
      "\n",
      "Missing values count per column:\n",
      "student_id         0\n",
      "name               0\n",
      "age                3\n",
      "grade              0\n",
      "score              0\n",
      "department         0\n",
      "enrollment_date    0\n",
      "email              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values (returns True/False for each cell)\n",
    "print(\"Missing values check:\")\n",
    "print(df.isna().head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Count missing values per column\n",
    "print(\"Missing values count per column:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 `df.value_counts()` - Count Unique Values for a Column\n",
    "\n",
    "**What it does:** Returns counts of unique values in a Series (column). It is very common when you are dealing with categorical variables. You can use it to understand the distribution of categorical variables or identify unexpected values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for 'grade' column:\n",
      "grade\n",
      "A    7\n",
      "B    7\n",
      "C    5\n",
      "a    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count unique values in 'grade' column\n",
    "print(\"Value counts for 'grade' column:\")\n",
    "print(df['grade'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Selection and Filtering\n",
    "\n",
    "Selecting and filtering data is fundamental to data analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Column Selection\n",
    "\n",
    "**Methods:**\n",
    "- `df['column_name']` - Select single column (returns Series)\n",
    "- `df[['col1', 'col2']]` - Select multiple columns (returns DataFrame)\n",
    "- `df.loc[]` - Label-based selection\n",
    "- `df.iloc[]` - Integer position-based selection\n",
    "\n",
    "**When to use:** To focus on specific variables or create subsets of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single column (Series):\n",
      "<class 'pandas.core.series.Series'>\n",
      "0          Alice\n",
      "1            Bob\n",
      "2      Charlie  \n",
      "3          Diana\n",
      "4            Eve\n",
      "Name: name, dtype: object\n",
      "\n",
      "==================================================\n",
      "\n",
      "Multiple columns (DataFrame):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "          name   age  score\n",
      "0        Alice  20.0     95\n",
      "1          Bob  21.0     85\n",
      "2    Charlie     NaN     92\n",
      "3        Diana  19.0     72\n",
      "4          Eve  22.0     88\n",
      "\n",
      "==================================================\n",
      "\n",
      "Using loc to select rows and columns:\n",
      "          name  score\n",
      "0        Alice     95\n",
      "1          Bob     85\n",
      "2    Charlie       92\n",
      "3        Diana     72\n",
      "4          Eve     88\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Select single column (returns Series)\n",
    "print(\"Single column (Series):\")\n",
    "print(type(df['name']))\n",
    "print(df['name'].head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 2: Select multiple columns (returns DataFrame)\n",
    "print(\"Multiple columns (DataFrame):\")\n",
    "print(type(df[['name', 'age', 'score']]))\n",
    "print(df[['name', 'age', 'score']].head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 3: Using loc for label-based selection\n",
    "print(\"Using loc to select rows and columns:\")\n",
    "print(df.loc[0:4, ['name', 'score']])  # Rows 0-4, specific columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Boolean Indexing / Filtering\n",
    "\n",
    "**What it does:** Filter rows based on conditions.\n",
    "\n",
    "**Syntax:** `df[condition]` or `df.loc[condition]`\n",
    "\n",
    "**When to use:** To subset data based on criteria (e.g., filter by date range, value thresholds, categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students with score > 90:\n",
      "           name  score grade\n",
      "0         Alice     95     A\n",
      "2     Charlie       92     A\n",
      "8           Ivy     94     A\n",
      "11         Liam     93     A\n",
      "12          Mia    150     B\n",
      "13         Noah     91     A\n",
      "16        Quinn     96     A\n",
      "\n",
      "==================================================\n",
      "\n",
      "CS students with score > 85:\n",
      "           name department  score\n",
      "0         Alice         CS     95\n",
      "2     Charlie           CS     92\n",
      "5         Frank         CS     90\n",
      "11         Liam         CS     93\n",
      "13         Noah         CS     91\n",
      "16        Quinn         CS     96\n",
      "19         Tina         CS     89\n",
      "\n",
      "==================================================\n",
      "\n",
      "Students in Math or Physics:\n",
      "    name department\n",
      "1    Bob       Math\n",
      "3  Diana    Physics\n",
      "4    Eve       Math\n",
      "6  Grace       Math\n",
      "7  Henry    Physics\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Filter rows where score > 90\n",
    "high_scores = df[df['score'] > 90]\n",
    "print(\"Students with score > 90:\")\n",
    "print(high_scores[['name', 'score', 'grade']])\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 2: Multiple conditions using & (and) or | (or)\n",
    "# Note: Each condition must be in parentheses\n",
    "cs_students_high_score = df[(df['department'] == 'CS') & (df['score'] > 85)]\n",
    "print(\"CS students with score > 85:\")\n",
    "print(cs_students_high_score[['name', 'department', 'score']])\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 3: Using isin() for multiple values\n",
    "math_or_physics = df[df['department'].isin(['Math', 'Physics'])]\n",
    "print(\"Students in Math or Physics:\")\n",
    "print(math_or_physics[['name', 'department']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Transformation\n",
    "\n",
    "Transform data to create new columns or modify existing ones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Creating New Columns\n",
    "\n",
    "**What it does:** Add new columns based on calculations or transformations of existing columns.\n",
    "\n",
    "**Methods:**\n",
    "- `df['new_col'] = values` - Direct assignment\n",
    "- `df.assign()` - Method chaining friendly\n",
    "- `df.apply()` - Apply function to rows/columns\n",
    "\n",
    "**When to use:** To create derived variables, perform calculations, or add metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New columns created:\n",
      "          name  score  score_percentage pass_fail\n",
      "0        Alice     95                95      Pass\n",
      "1          Bob     85                85      Pass\n",
      "2    Charlie       92                92      Pass\n",
      "3        Diana     72                72      Pass\n",
      "4          Eve     88                88      Pass\n",
      "\n",
      "==================================================\n",
      "\n",
      "Using assign() to create performance category:\n",
      "          name  score performance_category\n",
      "0        Alice     95                 High\n",
      "1          Bob     85               Medium\n",
      "2    Charlie       92                 High\n",
      "3        Diana     72               Medium\n",
      "4          Eve     88                 High\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Create new column with direct assignment\n",
    "df_copy = df.copy()\n",
    "df_copy['score_percentage'] = df_copy['score']  # Already a percentage, but renaming for clarity\n",
    "df_copy['pass_fail'] = df_copy['score'].apply(lambda x: 'Pass' if x >= 70 else 'Fail')\n",
    "print(\"New columns created:\")\n",
    "print(df_copy[['name', 'score', 'score_percentage', 'pass_fail']].head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 2: Using assign() for method chaining\n",
    "df_with_category = df.assign(\n",
    "    performance_category=lambda x: pd.cut(x['score'], \n",
    "                                         bins=[0, 70, 85, 100], \n",
    "                                         labels=['Low', 'Medium', 'High'])\n",
    ")\n",
    "print(\"Using assign() to create performance category:\")\n",
    "print(df_with_category[['name', 'score', 'performance_category']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 `df.apply()` - Apply Function to Rows or Columns\n",
    "\n",
    "**What it does:** Apply a function along an axis (rows or columns) of the DataFrame.\n",
    "\n",
    "**Key parameters:**\n",
    "- `func`: Function to apply\n",
    "- `axis`: 0 (apply to each column) or 1 (apply to each row)\n",
    "- `args`: Additional positional arguments to pass to function\n",
    "\n",
    "**When to use:** When you need to apply a custom function that can't be vectorized, or when working with complex row/column operations. You can self define a data cleaning function and apply it to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying function to create calculated grade:\n",
      "          name  score grade calculated_grade\n",
      "0        Alice     95     A                A\n",
      "1          Bob     85     B                B\n",
      "2    Charlie       92     A                A\n",
      "3        Diana     72     C                C\n",
      "4          Eve     88     B                B\n",
      "\n",
      "==================================================\n",
      "\n",
      "Mean of each numeric column:\n",
      "student_id    10.500000\n",
      "age           20.588235\n",
      "score         87.850000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Apply function to each row\n",
    "# Here we are converting to the numeric grade to a letter grade. We can define a function with the conversion rules and apply it to the dataframe.\n",
    "def calculate_grade_letter(score):\n",
    "    \"\"\"Convert numeric score to letter grade\"\"\"\n",
    "    if score >= 90:\n",
    "        return 'A'\n",
    "    elif score >= 80:\n",
    "        return 'B'\n",
    "    elif score >= 70:\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "df_copy2 = df.copy()\n",
    "df_copy2['calculated_grade'] = df_copy2['score'].apply(calculate_grade_letter)\n",
    "print(\"Applying function to create calculated grade:\")\n",
    "print(df_copy2[['name', 'score', 'grade', 'calculated_grade']].head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 2: Apply function to each column (axis=0)\n",
    "print(\"Mean of each numeric column:\")\n",
    "print(df.select_dtypes(include=[np.number]).apply(np.mean, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 `df.map()` - Map Values Using Dictionary or Function\n",
    "\n",
    "**What it does:** Map values of a Series according to an input mapping (dict, Series, or function).\n",
    "\n",
    "**When to use:** To replace values based on a mapping (e.g., rename categories, encode values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping department codes to full names:\n",
      "          name department   department_full\n",
      "0        Alice         CS  Computer Science\n",
      "1          Bob       Math       Mathematics\n",
      "2    Charlie           CS  Computer Science\n",
      "3        Diana    Physics           Physics\n",
      "4          Eve       Math       Mathematics\n"
     ]
    }
   ],
   "source": [
    "# Example: Map department codes to full names\n",
    "dept_mapping = {\n",
    "    'CS': 'Computer Science',\n",
    "    'Math': 'Mathematics',\n",
    "    'Physics': 'Physics'\n",
    "}\n",
    "\n",
    "df_copy3 = df.copy()\n",
    "df_copy3['department_full'] = df_copy3['department'].map(dept_mapping)\n",
    "print(\"Mapping department codes to full names:\")\n",
    "print(df_copy3[['name', 'department', 'department_full']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 `df.replace()` - Replace Values\n",
    "\n",
    "**What it does:** Replace values in DataFrame or Series.\n",
    "\n",
    "**When to use:** To correct data entry errors, standardize values, or replace specific values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before replacement:\n",
      "grade\n",
      "A    7\n",
      "B    7\n",
      "C    5\n",
      "a    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After replacing 'a' with 'A':\n",
      "grade\n",
      "A    8\n",
      "B    7\n",
      "C    5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Example: Replace values (fixing inconsistencies)\n",
    "df_copy4 = df.copy()\n",
    "print(\"Before replacement:\")\n",
    "print(df_copy4['grade'].value_counts())\n",
    "\n",
    "# Replace lowercase 'a' with uppercase 'A'\n",
    "df_copy4['grade'] = df_copy4['grade'].replace('a', 'A')\n",
    "print(\"\\nAfter replacing 'a' with 'A':\")\n",
    "print(df_copy4['grade'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. String Operations\n",
    "\n",
    "Pandas provides vectorized string operations through the `.str` accessor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 `df.str.strip()` - Remove Whitespace\n",
    "\n",
    "**What it does:** Remove leading and trailing whitespace from string values.\n",
    "\n",
    "**When to use:** To clean up data entry inconsistencies (extra spaces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before stripping (showing name with extra spaces):\n",
      "Name at index 2: '  Charlie  '\n",
      "\n",
      "After stripping: 'Charlie'\n"
     ]
    }
   ],
   "source": [
    "# Example: Strip whitespace from names\n",
    "df_copy5 = df.copy()\n",
    "print(\"Before stripping (showing name with extra spaces):\")\n",
    "print(f\"Name at index 2: '{df_copy5.loc[2, 'name']}'\")\n",
    "\n",
    "df_copy5['name'] = df_copy5['name'].str.strip()\n",
    "print(f\"\\nAfter stripping: '{df_copy5.loc[2, 'name']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 `df.str.upper()` / `df.str.lower()` - Case Conversion\n",
    "\n",
    "**What it does:** Convert strings to uppercase or lowercase.\n",
    "\n",
    "**When to use:** To standardize case for categorical variables or text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before standardization:\n",
      "department\n",
      "CS         7\n",
      "Math       7\n",
      "Physics    5\n",
      "cs         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After converting to uppercase:\n",
      "department\n",
      "CS         8\n",
      "MATH       7\n",
      "PHYSICS    5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Example: Standardize department names to uppercase\n",
    "df_copy6 = df.copy()\n",
    "print(\"Before standardization:\")\n",
    "print(df_copy6['department'].value_counts())\n",
    "\n",
    "df_copy6['department'] = df_copy6['department'].str.upper()\n",
    "print(\"\\nAfter converting to uppercase:\")\n",
    "print(df_copy6['department'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 `df.str.contains()` - Check for Substring\n",
    "\n",
    "**What it does:** Check if each string contains a pattern (returns boolean Series).\n",
    "\n",
    "**When to use:** To filter or flag rows based on text patterns (e.g., find emails from specific domain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with valid email format:\n",
      "          name              email\n",
      "0        Alice    alice@email.com\n",
      "1          Bob      bob@email.com\n",
      "2    Charlie    charlie@email.com\n",
      "3        Diana    diana@email.com\n",
      "4          Eve      eve@email.com\n",
      "\n",
      "==================================================\n",
      "\n",
      "Rows with invalid email format:\n",
      "    name          email\n",
      "15  Paul  invalid-email\n"
     ]
    }
   ],
   "source": [
    "# Example: Find rows where email contains '@email.com'\n",
    "valid_emails = df[df['email'].str.contains('@email.com', na=False)]\n",
    "print(\"Rows with valid email format:\")\n",
    "print(valid_emails[['name', 'email']].head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Find invalid emails\n",
    "invalid_emails = df[~df['email'].str.contains('@email.com', na=False)]\n",
    "print(\"Rows with invalid email format:\")\n",
    "print(invalid_emails[['name', 'email']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Type Conversion\n",
    "\n",
    "Converting data types is crucial for proper analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 `pd.to_datetime()` - Convert to DateTime\n",
    "\n",
    "**What it does:** Convert string or numeric values to datetime objects.\n",
    "\n",
    "**When to use:** When working with dates/times stored as strings, or when dates need to be parsed from various formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before conversion:\n",
      "Type: object\n",
      "          name enrollment_date\n",
      "0        Alice      2023-01-15\n",
      "1          Bob      2023-01-20\n",
      "2    Charlie        2023-02-01\n",
      "3        Diana      2023-01-10\n",
      "4          Eve      2023-02-15\n",
      "\n",
      "After conversion:\n",
      "Type: datetime64[ns]\n",
      "          name enrollment_date\n",
      "0        Alice      2023-01-15\n",
      "1          Bob      2023-01-20\n",
      "2    Charlie        2023-02-01\n",
      "3        Diana      2023-01-10\n",
      "4          Eve      2023-02-15\n",
      "\n",
      "==================================================\n",
      "\n",
      "Extracted date components:\n",
      "          name enrollment_date  enrollment_month  enrollment_year\n",
      "0        Alice      2023-01-15                 1             2023\n",
      "1          Bob      2023-01-20                 1             2023\n",
      "2    Charlie        2023-02-01                 2             2023\n",
      "3        Diana      2023-01-10                 1             2023\n",
      "4          Eve      2023-02-15                 2             2023\n"
     ]
    }
   ],
   "source": [
    "# Example: Convert enrollment_date from string to datetime\n",
    "df_copy7 = df.copy()\n",
    "print(\"Before conversion:\")\n",
    "print(f\"Type: {df_copy7['enrollment_date'].dtype}\")\n",
    "print(df_copy7[['name', 'enrollment_date']].head())\n",
    "\n",
    "df_copy7['enrollment_date'] = pd.to_datetime(df_copy7['enrollment_date'])\n",
    "print(\"\\nAfter conversion:\")\n",
    "print(f\"Type: {df_copy7['enrollment_date'].dtype}\")\n",
    "print(df_copy7[['name', 'enrollment_date']].head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Now we can extract date components\n",
    "df_copy7['enrollment_month'] = df_copy7['enrollment_date'].dt.month\n",
    "df_copy7['enrollment_year'] = df_copy7['enrollment_date'].dt.year\n",
    "print(\"Extracted date components:\")\n",
    "print(df_copy7[['name', 'enrollment_date', 'enrollment_month', 'enrollment_year']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 `df.astype()` - Convert Data Types\n",
    "\n",
    "**What it does:** Cast a pandas object to a specified dtype.\n",
    "\n",
    "**When to use:** To convert between numeric types, convert strings to numbers, or change data types for memory efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before conversion:\n",
      "Score dtype: int64\n",
      "\n",
      "After conversion:\n",
      "Score dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Example: Convert score from int64 to float64\n",
    "df_copy8 = df.copy()\n",
    "print(\"Before conversion:\")\n",
    "print(f\"Score dtype: {df_copy8['score'].dtype}\")\n",
    "\n",
    "df_copy8['score'] = df_copy8['score'].astype('float64')\n",
    "print(f\"\\nAfter conversion:\")\n",
    "print(f\"Score dtype: {df_copy8['score'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Grouping and Aggregation\n",
    "\n",
    "Grouping allows you to split data into groups and apply functions to each group. This is a very common and useful operation in the exploration analysis part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 `df.groupby()` - Group Data\n",
    "\n",
    "**What it does:** Split data into groups based on some criteria, then apply a function to each group independently.\n",
    "\n",
    "**When to use:** To calculate statistics by category, aggregate data, or perform group-level transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score by department:\n",
      "department\n",
      "CS         92.285714\n",
      "Math       94.142857\n",
      "Physics    71.600000\n",
      "cs         94.000000\n",
      "Name: score, dtype: float64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Summary statistics by department:\n",
      "                score                                  age\n",
      "                 mean        std min  max count       mean\n",
      "department                                                \n",
      "CS          92.285714   2.563480  89   96     7  20.666667\n",
      "Math        94.142857  24.721304  82  150     7  20.333333\n",
      "Physics     71.600000   2.701851  68   75     5  20.750000\n",
      "cs          94.000000        NaN  94   94     1  21.000000\n",
      "\n",
      "==================================================\n",
      "\n",
      "Mean score by department and grade:\n",
      "department  grade\n",
      "CS          A        92.666667\n",
      "            a        90.000000\n",
      "Math        B        94.142857\n",
      "Physics     C        71.600000\n",
      "cs          A        94.000000\n",
      "Name: score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Group by department and calculate mean score\n",
    "dept_stats = df.groupby('department')['score'].mean()\n",
    "print(\"Mean score by department:\")\n",
    "print(dept_stats)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 2: Multiple aggregations\n",
    "dept_summary = df.groupby('department').agg({\n",
    "    'score': ['mean', 'std', 'min', 'max', 'count'],\n",
    "    'age': 'mean'\n",
    "})\n",
    "print(\"Summary statistics by department:\")\n",
    "print(dept_summary)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 3: Group by multiple columns\n",
    "grade_dept_stats = df.groupby(['department', 'grade'])['score'].mean()\n",
    "print(\"Mean score by department and grade:\")\n",
    "print(grade_dept_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Sorting Data\n",
    "\n",
    "### 10.1 `df.sort_values()` - Sort by Column Values\n",
    "\n",
    "**What it does:** Sort DataFrame by one or more columns.\n",
    "\n",
    "**Key parameters:**\n",
    "- `by`: Column name(s) to sort by\n",
    "- `ascending`: True (ascending) or False (descending)\n",
    "- `na_position`: 'last' (default) or 'first' for NaN values\n",
    "\n",
    "**When to use:** To order data for analysis, find top/bottom values, or prepare data for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 students by score:\n",
      "     name  score grade department\n",
      "12    Mia    150     B       Math\n",
      "16  Quinn     96     A         CS\n",
      "0   Alice     95     A         CS\n",
      "8     Ivy     94     A         cs\n",
      "11   Liam     93     A         CS\n",
      "\n",
      "==================================================\n",
      "\n",
      "Sorted by department (ascending) then score (descending):\n",
      "           name department  score\n",
      "16        Quinn         CS     96\n",
      "0         Alice         CS     95\n",
      "11         Liam         CS     93\n",
      "2     Charlie           CS     92\n",
      "13         Noah         CS     91\n",
      "5         Frank         CS     90\n",
      "19         Tina         CS     89\n",
      "12          Mia       Math    150\n",
      "4           Eve       Math     88\n",
      "6         Grace       Math     87\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Sort by score (descending)\n",
    "sorted_by_score = df.sort_values('score', ascending=False)\n",
    "print(\"Top 5 students by score:\")\n",
    "print(sorted_by_score[['name', 'score', 'grade', 'department']].head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 2: Sort by multiple columns\n",
    "sorted_multi = df.sort_values(['department', 'score'], ascending=[True, False])\n",
    "print(\"Sorted by department (ascending) then score (descending):\")\n",
    "print(sorted_multi[['name', 'department', 'score']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Removing Duplicates\n",
    "\n",
    "### 11.1 `df.duplicated()` and `df.drop_duplicates()`\n",
    "\n",
    "**What it does:**\n",
    "- `duplicated()`: Returns boolean Series indicating duplicate rows\n",
    "- `drop_duplicates()`: Removes duplicate rows\n",
    "\n",
    "**Key parameters:**\n",
    "- `subset`: Columns to consider when identifying duplicates\n",
    "- `keep`: 'first' (keep first), 'last' (keep last), or False (drop all duplicates)\n",
    "\n",
    "**When to use:** To identify and remove duplicate records from your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with duplicates: 23 rows\n",
      "Number of duplicates: 3\n",
      "\n",
      "==================================================\n",
      "\n",
      "After dropping duplicates: 20 rows\n",
      "\n",
      "==================================================\n",
      "\n",
      "Rows with duplicate names:\n",
      "           name  student_id\n",
      "0         Alice           1\n",
      "1           Bob           2\n",
      "2     Charlie             3\n",
      "20        Alice           1\n",
      "21          Bob           2\n",
      "22    Charlie             3\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with duplicates for demonstration\n",
    "df_with_duplicates = pd.concat([df, df.iloc[[0, 1, 2]]], ignore_index=True)\n",
    "print(f\"DataFrame with duplicates: {len(df_with_duplicates)} rows\")\n",
    "print(f\"Number of duplicates: {df_with_duplicates.duplicated().sum()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Drop duplicates\n",
    "df_no_duplicates = df_with_duplicates.drop_duplicates()\n",
    "print(f\"After dropping duplicates: {len(df_no_duplicates)} rows\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Check for duplicates based on specific columns\n",
    "duplicates_by_name = df_with_duplicates.duplicated(subset=['name'], keep=False)\n",
    "print(\"Rows with duplicate names:\")\n",
    "print(df_with_duplicates[duplicates_by_name][['name', 'student_id']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Handling Missing Values\n",
    "\n",
    "Missing data is common in real-world datasets. Here are methods to handle it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 `df.dropna()` - Remove Rows/Columns with Missing Values\n",
    "\n",
    "**What it does:** Drops rows or columns containing missing values.\n",
    "\n",
    "**Key parameters:**\n",
    "- `axis`: 0 (rows, default) or 1 (columns)\n",
    "- `how`: 'any' (drop if any missing) or 'all' (drop if all missing)\n",
    "- `subset`: List of columns to check (only for axis=0)\n",
    "- `inplace`: If True, modifies DataFrame directly (default: False)\n",
    "\n",
    "**When to use:** When missing values are not informative and removing them won't bias your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 20\n",
      "After dropping rows with any missing values: 17\n",
      "\n",
      "==================================================\n",
      "\n",
      "After dropping rows with missing 'age': 17\n",
      "\n",
      "==================================================\n",
      "\n",
      "After dropping rows where ALL values are missing: 20\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Drop rows with ANY missing values\n",
    "df_dropped_any = df.dropna()\n",
    "print(f\"Original rows: {len(df)}\")\n",
    "print(f\"After dropping rows with any missing values: {len(df_dropped_any)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 2: Drop rows with missing values ONLY in 'age' column\n",
    "df_dropped_age = df.dropna(subset=['age'])\n",
    "print(f\"After dropping rows with missing 'age': {len(df_dropped_age)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 3: Drop rows where ALL values are missing (rare, but useful)\n",
    "df_dropped_all = df.dropna(how='all')\n",
    "print(f\"After dropping rows where ALL values are missing: {len(df_dropped_all)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 Impute Missing Values\n",
    "\n",
    "You are likely to deal with missing values in you assignments. Generally, there are two strategies: either remove the rows/columns with missing values, or impute the missing values based on what you know about the data. \n",
    "\n",
    "Be careful with the imputation, it might introduce bias to your data. Most of the time it is a good idea to keep the original data. If imputation is necessary, add a _new_ column with the imputed values. To start with imputation, you need to understand the missing pattern. Most importantly, you need to identify whether the values are missing at **random** or there is a dependency on other variables. If you use any of the following strategies, you need to justify your choice. \n",
    "\n",
    "Here are some common strategies for imputation:\n",
    "\n",
    "1. **Fill with a constant value**: e.g. `df.fillna(value=...)`\n",
    "2. **Fill with the mean/median/mode of the column**: e.g. `df.fillna(df.mean())`\n",
    "3. **Forward fill/Backward fill**: e.g. `df.ffill()` for forward fill, `df.bfill()` for backward fill\n",
    "4. **Interpolate**: Estimate the missing values based on the neighboring values and a presumed underlying data structure. e.g. `df.interpolate()`\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filling 'age' with 20:\n",
      "          name   age\n",
      "0        Alice  20.0\n",
      "1          Bob  21.0\n",
      "2    Charlie    20.0\n",
      "3        Diana  19.0\n",
      "4          Eve  22.0\n",
      "5        Frank  20.0\n",
      "6        Grace  20.0\n",
      "7        Henry  23.0\n",
      "8          Ivy  21.0\n",
      "9         Jack  20.0\n",
      "\n",
      "==================================================\n",
      "\n",
      "After filling 'age' with mean (20.59):\n",
      "          name        age\n",
      "0        Alice  20.000000\n",
      "1          Bob  21.000000\n",
      "2    Charlie    20.588235\n",
      "3        Diana  19.000000\n",
      "4          Eve  22.000000\n",
      "5        Frank  20.000000\n",
      "6        Grace  20.588235\n",
      "7        Henry  23.000000\n",
      "8          Ivy  21.000000\n",
      "9         Jack  20.000000\n",
      "\n",
      "==================================================\n",
      "\n",
      "After forward fill:\n",
      "          name   age\n",
      "0        Alice  20.0\n",
      "1          Bob  21.0\n",
      "2    Charlie    21.0\n",
      "3        Diana  19.0\n",
      "4          Eve  22.0\n",
      "5        Frank  20.0\n",
      "6        Grace  20.0\n",
      "7        Henry  23.0\n",
      "8          Ivy  21.0\n",
      "9         Jack  20.0\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Fill missing values with a constant\n",
    "df_filled_constant = df.copy()\n",
    "df_filled_constant['age'] = df_filled_constant['age'].fillna(20)  # Fill with mean age\n",
    "print(\"After filling 'age' with 20:\")\n",
    "print(df_filled_constant[['name', 'age']].head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 2: Fill with mean (common for numeric columns)\n",
    "mean_age = df['age'].mean()\n",
    "df_filled_mean = df.copy()\n",
    "df_filled_mean['age'] = df_filled_mean['age'].fillna(mean_age)\n",
    "print(f\"After filling 'age' with mean ({mean_age:.2f}):\")\n",
    "print(df_filled_mean[['name', 'age']].head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 3: Forward fill (carry last valid value forward)\n",
    "df_filled_ffill = df.copy()\n",
    "df_filled_ffill['age'] = df_filled_ffill['age'].ffill() \n",
    "print(\"After forward fill:\")\n",
    "print(df_filled_ffill[['name', 'age']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Handling Outliers\n",
    "\n",
    "### 13.1 Identifying and Handling Outliers\n",
    "\n",
    "**What it does:** Detect and handle extreme values that may be errors or need special treatment.\n",
    "\n",
    "Outliers may bias your analysis. But remember to remove them **only** if you have a good reason to do so. You will need to justify your choice in your report of whether you removed them or not.\n",
    "\n",
    "**Methods:**\n",
    "- Statistical methods (IQR, Z-score)\n",
    "- Domain knowledge\n",
    "- Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score statistics:\n",
      "Q1: 80.25, Q3: 92.25, IQR: 12.0\n",
      "Lower bound: 62.25, Upper bound: 110.25\n",
      "\n",
      "==================================================\n",
      "\n",
      "Outliers detected:\n",
      "   name  score\n",
      "12  Mia    150\n",
      "\n",
      "==================================================\n",
      "\n",
      "Original rows: 20\n",
      "After removing outliers: 19\n",
      "\n",
      "==================================================\n",
      "\n",
      "After capping outliers:\n",
      "   name   score\n",
      "12  Mia  110.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/s_ymht6j1vl62cxbn9rkd1jh0000gn/T/ipykernel_99236/3695171401.py:31: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '110.25' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_capped.loc[df_capped['score'] > upper_bound, 'score'] = upper_bound\n"
     ]
    }
   ],
   "source": [
    "# Example: Identify outliers using IQR method\n",
    "Q1 = df['score'].quantile(0.25)\n",
    "Q3 = df['score'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\"Score statistics:\")\n",
    "print(f\"Q1: {Q1}, Q3: {Q3}, IQR: {IQR}\")\n",
    "print(f\"Lower bound: {lower_bound}, Upper bound: {upper_bound}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Find outliers\n",
    "outliers = df[(df['score'] < lower_bound) | (df['score'] > upper_bound)]\n",
    "print(\"Outliers detected:\")\n",
    "print(outliers[['name', 'score']])\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Option 1: Remove outliers\n",
    "df_no_outliers = df[(df['score'] >= lower_bound) & (df['score'] <= upper_bound)]\n",
    "print(f\"Original rows: {len(df)}\")\n",
    "print(f\"After removing outliers: {len(df_no_outliers)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Option 2: Cap outliers (winsorization)\n",
    "df_capped = df.copy()\n",
    "df_capped.loc[df_capped['score'] > upper_bound, 'score'] = upper_bound\n",
    "df_capped.loc[df_capped['score'] < lower_bound, 'score'] = lower_bound\n",
    "print(\"After capping outliers:\")\n",
    "print(df_capped[df_capped['name'].isin(outliers['name'])][['name', 'score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Combining and Connecting DataFrames\n",
    "\n",
    "### 14.1 `pd.concat()` - Concatenate DataFrames\n",
    "\n",
    "**What it does:** Combine DataFrames along an axis (rows or columns).\n",
    "\n",
    "**Key parameters:**\n",
    "- `axis`: 0 (concatenate rows) or 1 (concatenate columns)\n",
    "- `ignore_index`: Reset index after concatenation\n",
    "\n",
    "**When to use:** To combine datasets with same columns (stacking) or same rows (side-by-side)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1:\n",
      "   student_id         name  score\n",
      "0           1        Alice     95\n",
      "1           2          Bob     85\n",
      "2           3    Charlie       92\n",
      "3           4        Diana     72\n",
      "4           5          Eve     88\n",
      "\n",
      "DataFrame 2:\n",
      "    student_id    name  score\n",
      "15          16    Paul     84\n",
      "16          17   Quinn     96\n",
      "17          18  Rachel     83\n",
      "18          19     Sam     73\n",
      "19          20    Tina     89\n",
      "\n",
      "==================================================\n",
      "\n",
      "After concatenating (stacking rows):\n",
      "   student_id         name  score\n",
      "0           1        Alice     95\n",
      "1           2          Bob     85\n",
      "2           3    Charlie       92\n",
      "3           4        Diana     72\n",
      "4           5          Eve     88\n",
      "5          16         Paul     84\n",
      "6          17        Quinn     96\n",
      "7          18       Rachel     83\n",
      "8          19          Sam     73\n",
      "9          20         Tina     89\n"
     ]
    }
   ],
   "source": [
    "# Create two sample DataFrames\n",
    "df1 = df[['student_id', 'name', 'score']].head(5)\n",
    "df2 = df[['student_id', 'name', 'score']].tail(5)\n",
    "\n",
    "print(\"DataFrame 1:\")\n",
    "print(df1)\n",
    "print(\"\\nDataFrame 2:\")\n",
    "print(df2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Concatenate vertically (stack rows)\n",
    "df_combined = pd.concat([df1, df2], ignore_index=True)\n",
    "print(\"After concatenating (stacking rows):\")\n",
    "print(df_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2 `pd.merge()` - Merge DataFrames\n",
    "\n",
    "**What it does:** Combine DataFrames based on common columns. It is extremely useful when you have multiple data sources and you need to combine them.\n",
    "\n",
    "**Key parameters:**\n",
    "- `on`: Column(s) to join on\n",
    "- `how`: 'inner', 'left', 'right', or 'outer'\n",
    "- `left_on` / `right_on`: Different column names in left/right DataFrames\n",
    "\n",
    "**When to use:** To combine datasets with related information (e.g., student info + grades)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Info DataFrame:\n",
      "   student_id         name   age department\n",
      "0           1        Alice  20.0         CS\n",
      "1           2          Bob  21.0       Math\n",
      "2           3    Charlie     NaN         CS\n",
      "3           4        Diana  19.0    Physics\n",
      "4           5          Eve  22.0       Math\n",
      "5           6        Frank  20.0         CS\n",
      "6           7        Grace   NaN       Math\n",
      "7           8        Henry  23.0    Physics\n",
      "8           9          Ivy  21.0         cs\n",
      "9          10         Jack  20.0       Math\n",
      "\n",
      "Student Scores DataFrame:\n",
      "   student_id  score grade\n",
      "0           1     95     A\n",
      "1           2     85     B\n",
      "2           3     92     A\n",
      "3           4     72     C\n",
      "4           5     88     B\n",
      "5           6     90     a\n",
      "6           7     87     B\n",
      "7           8     75     C\n",
      "\n",
      "==================================================\n",
      "\n",
      "Inner join (only matching student_ids):\n",
      "   student_id         name   age department  score grade\n",
      "0           1        Alice  20.0         CS     95     A\n",
      "1           2          Bob  21.0       Math     85     B\n",
      "2           3    Charlie     NaN         CS     92     A\n",
      "3           4        Diana  19.0    Physics     72     C\n",
      "4           5          Eve  22.0       Math     88     B\n",
      "5           6        Frank  20.0         CS     90     a\n",
      "6           7        Grace   NaN       Math     87     B\n",
      "7           8        Henry  23.0    Physics     75     C\n",
      "\n",
      "==================================================\n",
      "\n",
      "Left join (keep all students from info):\n",
      "   student_id         name  score grade\n",
      "0           1        Alice   95.0     A\n",
      "1           2          Bob   85.0     B\n",
      "2           3    Charlie     92.0     A\n",
      "3           4        Diana   72.0     C\n",
      "4           5          Eve   88.0     B\n",
      "5           6        Frank   90.0     a\n",
      "6           7        Grace   87.0     B\n",
      "7           8        Henry   75.0     C\n",
      "8           9          Ivy    NaN   NaN\n",
      "9          10         Jack    NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "# Create two related DataFrames\n",
    "student_info = df[['student_id', 'name', 'age', 'department']].head(10)\n",
    "student_scores = df[['student_id', 'score', 'grade']].head(8)  # Intentionally fewer rows\n",
    "\n",
    "print(\"Student Info DataFrame:\")\n",
    "print(student_info)\n",
    "print(\"\\nStudent Scores DataFrame:\")\n",
    "print(student_scores)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Inner join (only matching records)\n",
    "inner_merge = pd.merge(student_info, student_scores, on='student_id', how='inner')\n",
    "print(\"Inner join (only matching student_ids):\")\n",
    "print(inner_merge)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Left join (keep all from left DataFrame)\n",
    "left_merge = pd.merge(student_info, student_scores, on='student_id', how='left')\n",
    "print(\"Left join (keep all students from info):\")\n",
    "print(left_merge[['student_id', 'name', 'score', 'grade']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial covered essential pandas methods for data cleaning and manipulation:\n",
    "\n",
    "1. **Data Inspection**: `info()`, `describe()`, `head()`, `tail()`, `isna()`, `value_counts()`\n",
    "2. **Missing Values**: `dropna()`, `fillna()`\n",
    "3. **Selection & Filtering**: Column selection, boolean indexing\n",
    "4. **Transformation**: Creating columns, `apply()`, `map()`, `replace()`\n",
    "5. **String Operations**: `str.strip()`, `str.upper()`, `str.contains()`\n",
    "6. **Type Conversion**: `to_datetime()`, `astype()`\n",
    "7. **Grouping**: `groupby()` with aggregations\n",
    "8. **Sorting**: `sort_values()`\n",
    "9. **Duplicates**: `duplicated()`, `drop_duplicates()`\n",
    "10. **Outliers**: Detection and handling methods\n",
    "11. **Combining Data**: `concat()`, `merge()`\n",
    "\n",
    "**Best Practices:**\n",
    "- Always inspect your data first\n",
    "- Make copies before modifying (use `.copy()`)\n",
    "- Document your cleaning decisions and present them in your report.\n",
    "- Check data types and convert as needed\n",
    "- Handle missing values thoughtfully\n",
    "- Validate data quality (outliers, duplicates, formats)\n",
    "\n",
    "**Next Steps:**\n",
    "- Practice with your own datasets\n",
    "- Explore pandas documentation for advanced methods\n",
    "- Learn about `pd.pivot_table()` for reshaping data\n",
    "- Study `pd.melt()` and `pd.pivot()` for wide/long format conversions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
